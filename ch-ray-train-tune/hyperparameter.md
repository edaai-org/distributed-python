(sec-ray-tune)=
# Ray Tune

Ray Tune 主要针对机器学习实验和超参数调优的场景。这个场景往往需要启动多个实验，Ray Tune 对这种实验和调优做了封装，底层基于 Ray Task、Actor 和 Train 提供的能力。

## 超参数调优

{numref}`sec-machine-learning-intro` 中我们提到了模型的参数和超参数（Hyperparameter）的概念。超参数指的是模型参数（权重）之外的一些参数，比如深度学习模型训练时控制梯度下降速度的学习率，又比如决策树中分支的数量。确定这些超参数的方式是开启多个实验，每个实验测试超参数的某个值，根据模型训练结果的好坏来做选择，这个过程称为超参数调优。寻找最优超参数的过程这个过程可以手动进行，手动的话费时费力，效率地下，所以业界提出一些自动化的方法。自动化的方法包括以下几类：

* 网格搜索（Grid Search）：网格搜索是一种穷举搜索方法，它通过遍历所有可能的超参数组合来寻找最优解，这些组合会逐一被用来训练和评估模型。网格搜索简单直观，但当超参数空间很大时，所需的计算成本会急剧增加。
* 随机搜索（Random Search）：随机搜索不是遍历所有可能的组合，而是在解空间中随机选择超参数组合进行评估。这种方法的效率通常高于网格搜索，因为它不需要评估所有可能的组合，而是通过随机抽样来探索参数空间。随机搜索尤其适用于超参数空间非常大或维度很高的情况下，它可以在较少的尝试中发现性能良好的超参数配置。然而，由于随机性的存在，随机搜索可能会错过一些局部最优解，因此可能需要更多的尝试次数来确保找到一个好的解。
* 贝叶斯优化（Bayesian Optimization）：贝叶斯优化是一种基于贝叶斯定理的技术，它利用概率模型来指导搜索最优超参数的过程。这种方法的核心思想是构建一个贝叶斯模型，通常是高斯过程（Gaussian Process），来近似评估目标函数的未知部分。贝叶斯优化能够在有限的评估次数内，智能地选择最有希望的超参数组合进行尝试，特别适用于计算成本高昂的场景。

