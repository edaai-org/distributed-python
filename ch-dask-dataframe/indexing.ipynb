{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec-dask-dataframe-indexing)=\n",
    "# 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如 {numref}`fig-pandas-dataframe-model` 所示，pandas DataFrame 主要对二维的表进行处理，有列标签和行标签。行标签通常会被用户忽视，但实际上起着至关重要的作用，比如索引（Indexing）。大多数 pandas DataFrame 的行标签是排好序的索引，比如从 0 开始递增。 DataFrame 里面的数据也是有序的。\n",
    "\n",
    "```{figure} ../img/ch-dask-dataframe/dataframe-model.svg\n",
    "---\n",
    "width: 200px\n",
    "name: fig-pandas-dataframe-model\n",
    "---\n",
    "pandas DataFrame 数据模型\n",
    "```\n",
    "\n",
    "创建 pandas DataFrame 时，会在最左侧自动生成了索引列，它不是 DataFrame 的“官方”字段，因为索引列并没有列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baz</td>\n",
       "      <td>two</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qux</td>\n",
       "      <td>three</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B  C   D\n",
       "0  foo    one  1  10\n",
       "1  bar    one  2  20\n",
       "2  baz    two  3  30\n",
       "3  qux  three  4  40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "   'A': ['foo', 'bar', 'baz', 'qux'],\n",
    "   'B': ['one', 'one', 'two', 'three'],\n",
    "   'C': [1, 2, 3, 4],\n",
    "   'D': [10, 20, 30, 40]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以设置一个字段作为索引列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baz</th>\n",
       "      <td>two</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qux</th>\n",
       "      <td>three</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         B  C   D\n",
       "A                \n",
       "foo    one  1  10\n",
       "bar    one  2  20\n",
       "baz    two  3  30\n",
       "qux  three  4  40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('A')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者重置回原来的结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baz</td>\n",
       "      <td>two</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qux</td>\n",
       "      <td>three</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B  C   D\n",
       "0  foo    one  1  10\n",
       "1  bar    one  2  20\n",
       "2  baz    two  3  30\n",
       "3  qux  three  4  40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有序行索引\n",
    "\n",
    "Dask DataFrame 由多个 pandas DataFrame 组成，但如何在全局维度维护整个 Dask DataFrame 行标签和行顺序是一个很大的挑战。Dask DataFrame 并没有刻意保留全局有序性，也使得它无法支持所有 pandas DataFrame 的功能。\n",
    "\n",
    "如 {numref}`fig-dask-dataframe-divisions` 所示，Dask DataFrame 在切分时有 `divisions`。 \n",
    "\n",
    "```{figure} ../img/ch-dask-dataframe/divisions.svg\n",
    "---\n",
    "width: 400px\n",
    "name: fig-dask-dataframe-divisions\n",
    "---\n",
    "Dask DataFrame 的 `divisions`\n",
    "```\n",
    "\n",
    "以 Dask 提供的样例数据函数 `dask.datasets.timeseries` 为例，它生成了时间序列，使用时间戳作为行标签，每个 Partition 的边界都被记录下来，存储在 `.divisions` 里。`len(divisons)` 等于 `npartitions + 1`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.npartitions: 1826\n",
      "df.divisions: 1827\n"
     ]
    }
   ],
   "source": [
    "ts_df = dask.datasets.timeseries(\"2018-01-01\", \"2023-01-01\")\n",
    "print(f\"df.npartitions: {ts_df.npartitions}\")\n",
    "print(f\"df.divisions: {len(ts_df.divisions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask DataFrame 没有记录每个 Partition 中有多少行，因此无法在全局角度支持基于行索引的操作，比如 `iloc`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotImplementedError, 'DataFrame.iloc' only supports selecting columns. It must be used like 'df.iloc[:, column_indexer]'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ts_df.iloc[3].compute()\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}, {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是可以支持列标签，或者 `:` 这样的通配符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>984</td>\n",
       "      <td>0.660595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:01</th>\n",
       "      <td>960</td>\n",
       "      <td>-0.747564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:02</th>\n",
       "      <td>1039</td>\n",
       "      <td>0.777117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:03</th>\n",
       "      <td>1038</td>\n",
       "      <td>-0.501949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:04</th>\n",
       "      <td>992</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:59:55</th>\n",
       "      <td>1005</td>\n",
       "      <td>-0.102774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:59:56</th>\n",
       "      <td>1040</td>\n",
       "      <td>-0.648857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:59:57</th>\n",
       "      <td>1019</td>\n",
       "      <td>-0.310174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:59:58</th>\n",
       "      <td>987</td>\n",
       "      <td>0.889037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:59:59</th>\n",
       "      <td>977</td>\n",
       "      <td>-0.078216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157766400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id         x\n",
       "timestamp                          \n",
       "2018-01-01 00:00:00   984  0.660595\n",
       "2018-01-01 00:00:01   960 -0.747564\n",
       "2018-01-01 00:00:02  1039  0.777117\n",
       "2018-01-01 00:00:03  1038 -0.501949\n",
       "2018-01-01 00:00:04   992  0.767979\n",
       "...                   ...       ...\n",
       "2022-12-31 23:59:55  1005 -0.102774\n",
       "2022-12-31 23:59:56  1040 -0.648857\n",
       "2022-12-31 23:59:57  1019 -0.310174\n",
       "2022-12-31 23:59:58   987  0.889037\n",
       "2022-12-31 23:59:59   977 -0.078216\n",
       "\n",
       "[157766400 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df.iloc[:, [1, 2]].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 CSV 文件，Dask DataFrame 并没有自动生成 `divisions`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = os.path.join(os.getcwd(), \"../data/\")\n",
    "download_url = \"https://dp.godaai.org/nyc-flights.zip\"\n",
    "zip_file_path = os.path.join(folder_path, \"nyc-flights.zip\")\n",
    "if not os.path.exists(os.path.join(folder_path, \"nyc-flights\")):\n",
    "    with urllib.request.urlopen(download_url) as response, open(zip_file_path, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "        zf = ZipFile(zip_file_path, 'r')\n",
    "        zf.extractall(folder_path)\n",
    "        zf.close()\n",
    "file_path = os.path.join(folder_path, \"nyc-flights\", \"*.csv\")\n",
    "flights_ddf = dd.read_csv(file_path,\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': object,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})\n",
    "flights_ddf.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为没有记录每个 Partition 有多少条数据，Dask DataFrame 无法很好地支持一些操作，比如 `median()` 这样的百分位操作，因为这些操作需要：(1) 对数据排序；(2) 定位到特定的行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotImplementedError, Dask doesn't implement an exact median in all cases as this is hard to do in parallel. See the `median_approximate` method instead, which uses an approximate algorithm.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    flights_ddf['DepDelay'].median()\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}, {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置索引列\n",
    "\n",
    "### `set_index()`\n",
    "\n",
    "在 Dask DataFrame 中，我们可以使用 `set_index()` 方法手动设置某一列为索引列，这个操作除了设置某个字段为索引列，还会根据这个字段对全局数据进行排序，它打乱了原来每个 Partition 的数据排序，因此会有很高的成本。\n",
    "\n",
    "下面的例子展示了 `set_index()` 带来的变化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2\n",
      "0   01    a\n",
      "1   05    b\n",
      "2   02    c\n",
      "  col1 col2\n",
      "3   03    d\n",
      "4   04    e\n"
     ]
    }
   ],
   "source": [
    "def print_partitions(ddf):\n",
    "    for i in range(ddf.npartitions):\n",
    "        print(ddf.partitions[i].compute())\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"col1\": [\"01\", \"05\", \"02\", \"03\", \"04\"], \"col2\": [\"a\", \"b\", \"c\", \"d\", \"e\"]}\n",
    ")\n",
    "ddf = dd.from_pandas(df, npartitions=2)\n",
    "print_partitions(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col2\n",
      "col1     \n",
      "01      a\n",
      "     col2\n",
      "col1     \n",
      "02      c\n",
      "03      d\n",
      "04      e\n",
      "05      b\n"
     ]
    }
   ],
   "source": [
    "ddf2 = ddf.set_index(\"col1\")\n",
    "print_partitions(ddf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子设置 `col1` 列为索引列，2 个 Partition 中的数据被打乱重排。如果是在数据量很大的场景，全局数据排序和重分布的成本极高。因此应该尽量避免这个操作。`set_index()` 也有它的优势，它可以加速下游的计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到时间序列数据，该数据使用时间戳作为索引列。下面使用了两种方式对这份数据 `set_index()`。第一种没有设置 `divisions`，第二种设置了 `divisions`。\n",
    "\n",
    "第一种不设置 `divisions` 耗时很长，因为 Dask DataFrame 计算了所有 Partiton 的数据分布，并根据分布重排列了所有的 Partition，可以看到，Partition 的数目也发生了变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before set_index npartitions: 1826\n",
      "after set_index npartitions: 163\n",
      "CPU times: user 6.1 s, sys: 3.47 s, total: 9.57 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_df1 = ts_df.set_index(\"id\")\n",
    "nu =  ts_df1.loc[[1001]].name.nunique().compute()\n",
    "print(f\"before set_index npartitions: {ts_df.npartitions}\")\n",
    "print(f\"after set_index npartitions: {ts_df1.npartitions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种方式先提前获取了 `divisions`，然后将这些 `divisions` 用于设置 `set_index()`。设定 `division` 的 `set_index()` 速度更快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_computed_divisions = ts_df.set_index(\"id\").divisions\n",
    "unique_divisions = list(dict.fromkeys(list(dask_computed_divisions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 1.09 s, total: 4.34 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_df2 = ts_df.set_index(\"id\", divisions=unique_divisions)\n",
    "nuids = ts_df2.loc[[1001]].name.nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不设置索引列，直接对 `id` 列进行查询，发现反而更快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.94 s, sys: 743 ms, total: 2.68 s\n",
      "Wall time: 8.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nu = ts_df.loc[ts_df[\"id\"] == 1001].name.nunique().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以 Dask DataFrame 要慎重使用 `set_index()`，如果 `set_index()` 之后有很多以下操作，可以考虑使用 `set_index()`。\n",
    "\n",
    "* 使用 `loc` 对索引列进行过滤\n",
    "* 两个 Dask DataFrame 在索引列上合并（`merge()`）\n",
    "* 在索引列上进行分组聚合（`groupby()`）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `reset_index()`\n",
    "\n",
    "在 pandas 中，默认 `as_index=True` 时，分组字段经过 `groupby()` 之后成为索引列。索引列在 DataFrame 中并不是正式的数据列，如果分组聚合之后只有一个字段（不考虑分组字段），分组聚合的结果就成了一个 `Series`。比如下面 pandas 的例子，`Origin` 列就是分组字段，如果不设置 `as_index=False`，`groupby(\"Origin\", as_index=False)[\"DepDelay\"].mean()` 生成的是一个 `Series`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>AvgDepDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGA</td>\n",
       "      <td>5.726304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EWR</td>\n",
       "      <td>6.916220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFK</td>\n",
       "      <td>9.311532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin  AvgDepDelay\n",
       "2    LGA     5.726304\n",
       "0    EWR     6.916220\n",
       "1    JFK     9.311532"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas\n",
    "file_path = os.path.join(folder_path, \"nyc-flights\", \"1991.csv\")\n",
    "pdf = pd.read_csv(file_path,\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': object,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})\n",
    "uncancelled_pdf = pdf[pdf[\"Cancelled\"] == False]\n",
    "avg_pdf = uncancelled_pdf.groupby(\"Origin\", as_index=False)[\"DepDelay\"].mean()\n",
    "avg_pdf.columns = [\"Origin\", \"AvgDepDelay\"]\n",
    "avg_pdf.sort_values(\"AvgDepDelay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者是 `reset_index()`，来取消索引列，分组字段会成为 `DataFrame` 的一个正式的字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>AvgDepDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGA</td>\n",
       "      <td>5.726304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EWR</td>\n",
       "      <td>6.916220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFK</td>\n",
       "      <td>9.311532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin  AvgDepDelay\n",
       "2    LGA     5.726304\n",
       "0    EWR     6.916220\n",
       "1    JFK     9.311532"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pdf = uncancelled_pdf.groupby(\"Origin\")[\"DepDelay\"].mean().reset_index()\n",
    "avg_pdf.columns = [\"Origin\", \"AvgDepDelay\"]\n",
    "avg_pdf.sort_values(\"AvgDepDelay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask DataFrame 的 `groupby()` 不支持 `as_index` 参数。Dask DataFrame 只能使用 `reset_index()` 来取消索引列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>AvgDepDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGA</td>\n",
       "      <td>6.944939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EWR</td>\n",
       "      <td>9.997188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFK</td>\n",
       "      <td>10.766914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin  AvgDepDelay\n",
       "2    LGA     6.944939\n",
       "0    EWR     9.997188\n",
       "1    JFK    10.766914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncancelled_ddf = flights_ddf[flights_ddf[\"Cancelled\"] == False]\n",
    "avg_ddf = uncancelled_ddf.groupby(\"Origin\")[\"DepDelay\"].mean().reset_index()\n",
    "avg_ddf.columns = [\"Origin\", \"AvgDepDelay\"]\n",
    "avg_ddf = avg_ddf.compute()\n",
    "# pandas 只使用了一年数据，因此结果不一样\n",
    "avg_ddf.sort_values(\"AvgDepDelay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
