# MPI 与大模型

本章主要解释大模型的并行方法。大模型指的是神经网络的参数量很大，必须并行地进行训练和推理。大模型并行有如下特点：

* 计算运行在 GPU 这样的加速卡上；
* 加速卡非常昂贵，应尽量提高加速卡的利用率；
* 模型参数量大，无论是训练还是推理，可能有大量数据需要在加速卡之间传输，对带宽和延迟的要求都很高。

本章主要从概念和原理上进行解读，具体的实现可参考其他论文和开源库。

```{tableofcontents}
```