{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec-remote-memory-access)=\n",
    "# 远程内存访问\n",
    "\n",
    "{numref}`sec-mpi-hello-world` 中我们介绍了两种通信模式，即双边和单边。前几章节的点对点通信和集合通信主要针对的双边通信，本节主要介绍单边通信。单边通信是进程间直接访问远程内存，又称为远程内存访问（Remote Memory Access，RMA）。\n",
    "\n",
    "## Window\n",
    "\n",
    "任何进程所分配的内存都是私有的，即只被进程自己访问，远程内存访问要把进程自己的内存区域暴露给其他进程访问，这部分内存不再私有，而变成了公共的，需要特别处理。在 MPI 中，使用窗口（Window）定义可被远程访问的内存区域。某个内存区域被设置为允许远程访问，所有 Window 内的进程都可对这个区域进行读写。{numref}`fig-rma-window` 展示了私有的内存区域和可被远程访问的 Window。mpi4py 提供了 [`mpi4py.MPI.Win`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win) 类进行 Window 相关操作。\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-window.svg\n",
    "---\n",
    "width: 600px\n",
    "name: fig-rma-window\n",
    "---\n",
    "进程私有内存与允许远程访问的 Window\n",
    "```\n",
    "\n",
    "## 创建 Window\n",
    "\n",
    "我们可以使用 [`mpi4py.MPI.Win.Allocate`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Allocate) 和 [`mpi4py.MPI.Win.Create`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Create) 创建 Window。其中 `mpi4py.MPI.Win.Allocate` 创建新的内存缓存，并且该缓存可被远程访问；`mpi4py.MPI.Win.Create` 将现有的某个内存缓存区域设置为可远程访问。这个区别主要体现在这两个方法的第一个参数，`mpi4py.MPI.Win.Allocate(size)` 传入的要创建内存缓存的字节数 `size`； `mpi4py.MPI.Win.Create(memory)` 传入的是内存地址 `memory`。\n",
    "\n",
    "## 读写操作\n",
    "\n",
    "创建好可远程访问的 Window 后，可以使用三类方法来向内存区域读写数据：[`mpi4py.MPI.Win.Put`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Put)，[`mpi4py.MPI.Win.Get`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Get) 和 [`mpi4py.MPI.Win.Accumulate`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Accumulate)。这三类方法都有两个参数：`origin` 和 `target_rank`，分别表示源进程和目标进程。源进程指的是调用读写方法的进程，目标进程是被读写的进程。\n",
    "\n",
    "* `Win.Put` 将数据从源进程移动至目标进程。\n",
    "* `Win.Get` 将数据从目标进程移动至源进程。\n",
    "* `Win.Accumulate` 与 `Win.Put` 类似，也是将数据从源进程移动至目标进程，同时对源进程的数据和目标进程的数据进行了聚合操作，聚合操作的操作符包括：[`mpi4py.MPI.SUM`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.SUM.html)、[`mpi4py.MPI.PROD`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.PROD.html) 等。\n",
    "\n",
    "## 数据同步\n",
    "\n",
    "单机程序是顺序执行的，多机环境下，因为涉及多方数据的读写，可能会出现一些数据同步的问题，如 {numref}`fig-rma-sync-problem` 所示，如果不明确读写操作的顺序，尤其是短时间内同时执行 PUT 会导致某块内存区域的数据并非为程序员所期望的结果。\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-sync-problem.svg\n",
    "---\n",
    "width: 600px\n",
    "name: fig-rma-sync-problem\n",
    "---\n",
    "并行数据读写时会出现数据同步的问题，P0 和 P1 表示两个不同的进程。\n",
    "```\n",
    "\n",
    "为解决这个问题，需要一定的数据同步机制。MPI 一共有几类，包括主动同步（Active Target Synchronization）和被动同步（Passive Target Synchronization），如 {numref}`fig-rma-synchronization` 所示。\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-synchronization.svg\n",
    "---\n",
    "width: 600px\n",
    "name: fig-rma-synchronization\n",
    "---\n",
    "主动同步与被动同步\n",
    "```\n",
    "\n",
    "## 案例：远程读写\n",
    "\n",
    "一个完整的 RMA 程序应该包括：\n",
    "\n",
    "1. 创建 Window\n",
    "2. 数据同步\n",
    "3. 数据读写\n",
    "\n",
    "{numref}`code-mpi-rma-lock` 展示了一个案例，其代码保存为 `rma-lock.py`。\n",
    "\n",
    "```{code-block} python\n",
    ":caption: rma-lock.py\n",
    ":name: code-mpi-rma-lock\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "from mpi4py.util import dtlib\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "datatype = MPI.FLOAT\n",
    "np_dtype = dtlib.to_numpy_dtype(datatype)\n",
    "itemsize = datatype.Get_size()\n",
    "\n",
    "N = 8\n",
    "win_size = N * itemsize if rank == 0 else 0\n",
    "win = MPI.Win.Allocate(win_size, comm=comm)\n",
    "\n",
    "buf = np.empty(N, dtype=np_dtype)\n",
    "if rank == 0:\n",
    "    buf.fill(42)\n",
    "    win.Lock(rank=0)\n",
    "    win.Put(buf, target_rank=0)\n",
    "    win.Unlock(rank=0)\n",
    "    comm.Barrier()\n",
    "else:\n",
    "    comm.Barrier()\n",
    "    win.Lock(rank=0)\n",
    "    win.Get(buf, target_rank=0)\n",
    "    win.Unlock(rank=0)\n",
    "    if np.all(buf == 42):\n",
    "        print(f\"win.Get successfully on Rank {comm.Get_rank()}.\")\n",
    "    else:\n",
    "        print(f\"win.Get failed on Rank {comm.Get_rank()}.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win.Get successfully on Rank 4.\n",
      "win.Get successfully on Rank 5.\n",
      "win.Get successfully on Rank 6.\n",
      "win.Get successfully on Rank 7.\n",
      "win.Get successfully on Rank 1.\n",
      "win.Get successfully on Rank 2.\n",
      "win.Get successfully on Rank 3.\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -np 8 python rma_lock.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
